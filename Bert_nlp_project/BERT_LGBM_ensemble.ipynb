{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be05301",
   "metadata": {},
   "source": [
    "### Competition aim and summary of our project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93eac8f8",
   "metadata": {},
   "source": [
    "The project involved a competition between groups of students from the master's program to predict whether movie reviews on IMDb were positive or negative. The data provided by the professors was intentionally made dirty and unorganized to better represent a real-world scenario. The aim of the competition was to test our skills in:\n",
    "\n",
    "- cleaning and preprocessing data using Pyspark,\n",
    "- finding and scraping additional data online and merging it with the existing data, and\n",
    "- using machine learning techniques to create an innovative and performant model on the competition's validation and test sets.\n",
    "\n",
    "First, we successfully cleaned and preprocessed the data, which can be found in this notebook: https://github.com/Matei9721/Big-Data-Project/blob/feature/pipeline/notebooks/data_cleaning.ipynb. \n",
    "The variables that we used in our machine learning model were: 'runtime minutes of the movie,' 'number of votes (reviews),' and 'year of the movie.'\n",
    "\n",
    "We then collected three new variables: 'plots' of the movies, 'awarded' movies, and 'genres.' We extracted the 'plots' and 'awards' using GPT-3, with a prompt containing the movie's title, minutes, and year. The 'genre' variable was extracted from an online dataset that scraped Wikipedia.\n",
    "\n",
    "Here comes the fun ML part!! I trained a BERT model using just the 'plots' variable, while all the remaining features were used to train a Light Gradient Boosting Model (LGBM). Initially, I used the output of the BERT model (first tried with labels, then found out that raw probabilities were better) to create a new feature, which I added to the LGBM. This gave us a high accuracy of 81% on the competition's validation and testing sets. However, our accuracy on the test set that came from our train-test split was 10% higher than the competition's due to data leakage.\n",
    "\n",
    "To solve this issue, I made the models independent and computed predictions for both models, which I then averaged (essentially, I was doing ensembling). This approach improved the accuracy on the competition's test set to 82.5%. To further improve the accuracy, I decided to use four different BERT models instead of just one, resulting in ensembling five models (four BERTs and one LGBM) and a final accuracy of 84%, outperforming all other groups by 3.5%.\n",
    "\n",
    "The code for the machine learning pipeline can be found below. Please note that I have removed or simplified certain parts to better showcase the pipeline to the reader.\n",
    "\n",
    "P.S. The GitHub repo of the complete project is here: https://github.com/Matei9721/Big-Data-Project/tree/feature/pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90bdbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:27.932589Z",
     "iopub.status.busy": "2023-03-23T10:03:27.932052Z",
     "iopub.status.idle": "2023-03-23T10:03:27.939908Z",
     "shell.execute_reply": "2023-03-23T10:03:27.938772Z",
     "shell.execute_reply.started": "2023-03-23T10:03:27.932542Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16bab6",
   "metadata": {},
   "source": [
    "### Prepare text data for the Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd7a09d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:25:57.946216Z",
     "iopub.status.busy": "2023-03-23T11:25:57.945815Z",
     "iopub.status.idle": "2023-03-23T11:25:58.071117Z",
     "shell.execute_reply": "2023-03-23T11:25:58.070097Z",
     "shell.execute_reply.started": "2023-03-23T11:25:57.946179Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/train-val-test-bert/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4ab46c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:25:58.462108Z",
     "iopub.status.busy": "2023-03-23T11:25:58.461317Z",
     "iopub.status.idle": "2023-03-23T11:25:58.469949Z",
     "shell.execute_reply": "2023-03-23T11:25:58.468893Z",
     "shell.execute_reply.started": "2023-03-23T11:25:58.462074Z"
    }
   },
   "outputs": [],
   "source": [
    "#change label type\n",
    "train['label'] = train['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0483ea97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:25:59.120431Z",
     "iopub.status.busy": "2023-03-23T11:25:59.119263Z",
     "iopub.status.idle": "2023-03-23T11:25:59.137289Z",
     "shell.execute_reply": "2023-03-23T11:25:59.136291Z",
     "shell.execute_reply.started": "2023-03-23T11:25:59.120372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the doll is a 1919 silent film directed by e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the way down east is a 1920 silent film dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>destiny is a 1921 german silent fantasy film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the navigator is a 1924 silent comedy film s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the phantom of the opera is a 1925 silent ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                plot  label\n",
       "0    the doll is a 1919 silent film directed by e...      1\n",
       "1    the way down east is a 1920 silent film dire...      1\n",
       "2    destiny is a 1921 german silent fantasy film...      1\n",
       "3    the navigator is a 1924 silent comedy film s...      1\n",
       "4    the phantom of the opera is a 1925 silent ho...      1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['plot', 'label']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d40799e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:35.501068Z",
     "iopub.status.busy": "2023-03-23T10:03:35.500146Z",
     "iopub.status.idle": "2023-03-23T10:03:35.519810Z",
     "shell.execute_reply": "2023-03-23T10:03:35.518434Z",
     "shell.execute_reply.started": "2023-03-23T10:03:35.501031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7959 entries, 0 to 7958\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   plot    7959 non-null   object\n",
      " 1   label   7959 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 124.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#see if null values\n",
    "train.info()abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e70254d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:37.271300Z",
     "iopub.status.busy": "2023-03-23T10:03:37.270297Z",
     "iopub.status.idle": "2023-03-23T10:03:37.561582Z",
     "shell.execute_reply": "2023-03-23T10:03:37.559769Z",
     "shell.execute_reply.started": "2023-03-23T10:03:37.271251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length: 366 \n",
      "max length: 776\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see distribution of characters in plots. \n",
    "#The less the variance the less truncation and padding will be done and bert will perform better\n",
    "lengths = []\n",
    "for i, sentence in enumerate(train['plot']):\n",
    "    lengths.append(len(sentence))\n",
    "    \n",
    "plt.hist(lengths, bins=20);  \n",
    "print('min length:', min(lengths),'\\nmax length:',max(lengths))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43068b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:56:41.767551Z",
     "iopub.status.busy": "2023-03-22T11:56:41.767203Z",
     "iopub.status.idle": "2023-03-22T11:56:41.781107Z",
     "shell.execute_reply": "2023-03-22T11:56:41.779968Z",
     "shell.execute_reply.started": "2023-03-22T11:56:41.767520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in 1968, a small town in the midwest is rock...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hawaizaada is a 2015 indian biographical dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the beverly hillbillies is a 1993 comedy fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the man who came to dinner is a 1942 comedy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the black godfather is a biographical drama ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                plot  label\n",
       "0    in 1968, a small town in the midwest is rock...      0\n",
       "1    hawaizaada is a 2015 indian biographical dra...      0\n",
       "2    the beverly hillbillies is a 1993 comedy fil...      0\n",
       "3    the man who came to dinner is a 1942 comedy ...      1\n",
       "4    the black godfather is a biographical drama ...      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NEW TRAIN TEST SPLIT (this randomization is the same for this notebook and the lightgbm notebook)\n",
    "train = train.sample(frac=1, random_state=420).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124955a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:41.334737Z",
     "iopub.status.busy": "2023-03-23T10:03:41.333468Z",
     "iopub.status.idle": "2023-03-23T10:03:56.218474Z",
     "shell.execute_reply": "2023-03-23T10:03:56.217173Z",
     "shell.execute_reply.started": "2023-03-23T10:03:41.334681Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c14f656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:56.227657Z",
     "iopub.status.busy": "2023-03-23T10:03:56.224654Z",
     "iopub.status.idle": "2023-03-23T10:03:56.362522Z",
     "shell.execute_reply": "2023-03-23T10:03:56.361074Z",
     "shell.execute_reply.started": "2023-03-23T10:03:56.227614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed98790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:56.371308Z",
     "iopub.status.busy": "2023-03-23T10:03:56.368304Z",
     "iopub.status.idle": "2023-03-23T10:03:58.951020Z",
     "shell.execute_reply": "2023-03-23T10:03:58.949878Z",
     "shell.execute_reply.started": "2023-03-23T10:03:56.371267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc8832058e446e293a3b89716dee737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6679e1faa10b46849df7e5a9a605547f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5131fa12541659687ac5082f783c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original plot: A young woman falls in love with a man who is secretly a prince.\n",
      "\n",
      "Tokenized plot: ['[CLS]', 'a', 'young', 'woman', 'falls', 'in', 'love', 'with', 'a', 'man', 'who', 'is', 'secretly', 'a', 'prince', '.', '[SEP]']\n",
      "\n",
      "Token IDs: [101, 1037, 2402, 2450, 4212, 1999, 2293, 2007, 1037, 2158, 2040, 2003, 10082, 1037, 3159, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "# Example movie plot\n",
    "plot = list(train['plot'].values)[0]\n",
    "plot = \"A young woman falls in love with a man who is secretly a prince.\"\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the plot using the tokenizer's encode() method\n",
    "tokens = tokenizer.encode(plot, add_special_tokens=True)\n",
    "\n",
    "# The tokens variable now contains the token IDs of the tokenized plot\n",
    "print('Original plot:', plot)\n",
    "print()\n",
    "print('Tokenized plot:', tokenizer.convert_ids_to_tokens(tokens))\n",
    "print()\n",
    "print('Token IDs:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42d29c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:03:58.953937Z",
     "iopub.status.busy": "2023-03-23T10:03:58.953482Z",
     "iopub.status.idle": "2023-03-23T10:04:23.013180Z",
     "shell.execute_reply": "2023-03-23T10:04:23.012164Z",
     "shell.execute_reply.started": "2023-03-23T10:03:58.953898Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_len = 128 # maximum sequence length to use\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#encoded_plots = tokenizer.batch_encode_plus(list(train['plot'].values), add_special_tokens=True, max_length=max_len, pad_to_max_length=True, truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "encoded_plots = tokenizer.batch_encode_plus(list(train['plot'].values), add_special_tokens=True, max_length=max_len, \n",
    "                                            padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b37041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:04:23.015094Z",
     "iopub.status.busy": "2023-03-23T10:04:23.014741Z",
     "iopub.status.idle": "2023-03-23T10:04:23.022007Z",
     "shell.execute_reply": "2023-03-23T10:04:23.020975Z",
     "shell.execute_reply.started": "2023-03-23T10:04:23.015053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7959, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_plots['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08cbc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:04:23.024254Z",
     "iopub.status.busy": "2023-03-23T10:04:23.023580Z",
     "iopub.status.idle": "2023-03-23T10:04:23.058989Z",
     "shell.execute_reply": "2023-03-23T10:04:23.058010Z",
     "shell.execute_reply.started": "2023-03-23T10:04:23.024203Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_tensor = torch.tensor(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3931d",
   "metadata": {},
   "source": [
    "### Old Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c079bce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:02:13.735212Z",
     "iopub.status.busy": "2023-03-20T14:02:13.734801Z",
     "iopub.status.idle": "2023-03-20T14:02:13.743336Z",
     "shell.execute_reply": "2023-03-20T14:02:13.742006Z",
     "shell.execute_reply.started": "2023-03-20T14:02:13.735171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a TensorDataset and DataLoader for training and validation\n",
    "dataset = TensorDataset(encoded_plots['input_ids'], encoded_plots['attention_mask'], labels_tensor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3ac3f",
   "metadata": {},
   "source": [
    "### New shuffle (same to lightGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca07dc5",
   "metadata": {},
   "source": [
    "#### we need to train Bert and the LGBM on the same split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cc2b5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T09:26:47.576723Z",
     "iopub.status.busy": "2023-03-22T09:26:47.576325Z",
     "iopub.status.idle": "2023-03-22T09:26:47.584228Z",
     "shell.execute_reply": "2023-03-22T09:26:47.583134Z",
     "shell.execute_reply.started": "2023-03-22T09:26:47.576689Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train))\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    encoded_plots['input_ids'][:train_size], \n",
    "    encoded_plots['attention_mask'][:train_size], \n",
    "    labels_tensor[:train_size]\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    encoded_plots['input_ids'][train_size:], \n",
    "    encoded_plots['attention_mask'][train_size:], \n",
    "    labels_tensor[train_size:]\n",
    ")\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #cambiaaa\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "535e2e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T09:26:47.587205Z",
     "iopub.status.busy": "2023-03-22T09:26:47.585786Z",
     "iopub.status.idle": "2023-03-22T09:26:47.596303Z",
     "shell.execute_reply": "2023-03-22T09:26:47.595309Z",
     "shell.execute_reply.started": "2023-03-22T09:26:47.587177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    0\n",
       "14    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "train['label'][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a9870a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T15:02:49.397153Z",
     "iopub.status.busy": "2023-03-20T15:02:49.396406Z",
     "iopub.status.idle": "2023-03-20T15:02:49.405113Z",
     "shell.execute_reply": "2023-03-20T15:02:49.403749Z",
     "shell.execute_reply.started": "2023-03-20T15:02:49.397115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(batch[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdaa1f",
   "metadata": {},
   "source": [
    "## Bert Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "274bdf2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:12:40.122747Z",
     "iopub.status.busy": "2023-03-23T10:12:40.121798Z",
     "iopub.status.idle": "2023-03-23T10:12:42.010025Z",
     "shell.execute_reply": "2023-03-23T10:12:42.009106Z",
     "shell.execute_reply.started": "2023-03-23T10:12:40.122696Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model and add a classification layer on top of it\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "701b03c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T09:27:06.347756Z",
     "iopub.status.busy": "2023-03-22T09:27:06.347134Z",
     "iopub.status.idle": "2023-03-22T09:32:12.673947Z",
     "shell.execute_reply": "2023-03-22T09:32:12.672852Z",
     "shell.execute_reply.started": "2023-03-22T09:27:06.347718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch 0 out of 397 is done\n",
      "epoch:0, batch 50 out of 397 is done\n",
      "epoch:0, batch 100 out of 397 is done\n",
      "epoch:0, batch 150 out of 397 is done\n",
      "epoch:0, batch 200 out of 397 is done\n",
      "epoch:0, batch 250 out of 397 is done\n",
      "epoch:0, batch 300 out of 397 is done\n",
      "epoch:0, batch 350 out of 397 is done\n",
      "Epoch 1/2, Validation Loss: 0.5062, Validation Accuracy: 0.7745\n",
      "epoch:1, batch 0 out of 397 is done\n",
      "epoch:1, batch 50 out of 397 is done\n",
      "epoch:1, batch 100 out of 397 is done\n",
      "epoch:1, batch 150 out of 397 is done\n",
      "epoch:1, batch 200 out of 397 is done\n",
      "epoch:1, batch 250 out of 397 is done\n",
      "epoch:1, batch 300 out of 397 is done\n",
      "epoch:1, batch 350 out of 397 is done\n",
      "Epoch 2/2, Validation Loss: 0.4896, Validation Accuracy: 0.7789\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Fine-tune the BERT model\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad() #set the gradients to zero for each batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #clip the gradients to a maximum value of 1.0, prevent exploding gradient\n",
    "        \n",
    "        #parameter update based on the current gradient (stored in . grad attribute of a parameter)\n",
    "        optimizer.step()\n",
    "        \n",
    "        #update learning rate with scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f'epoch:{epoch}, batch {i} out of {len(train_dataset)//batch_size} is done')\n",
    "\n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_accuracy += torch.sum(preds == labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_val_accuracy = val_accuracy / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb14f27",
   "metadata": {},
   "source": [
    "### Bert on ALL dataset (RUN ONLY IF YOU WANT TO TRAIN ON 100% OF DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c06c6b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:12:53.317915Z",
     "iopub.status.busy": "2023-03-23T10:12:53.317017Z",
     "iopub.status.idle": "2023-03-23T10:12:53.323503Z",
     "shell.execute_reply": "2023-03-23T10:12:53.322321Z",
     "shell.execute_reply.started": "2023-03-23T10:12:53.317876Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = TensorDataset(encoded_plots['input_ids'], encoded_plots['attention_mask'], labels_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40afa738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:12:54.773219Z",
     "iopub.status.busy": "2023-03-23T10:12:54.772826Z",
     "iopub.status.idle": "2023-03-23T10:12:54.780576Z",
     "shell.execute_reply": "2023-03-23T10:12:54.779178Z",
     "shell.execute_reply.started": "2023-03-23T10:12:54.773184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "0.8*len(dataset)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75f09d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:12:55.796278Z",
     "iopub.status.busy": "2023-03-23T10:12:55.795361Z",
     "iopub.status.idle": "2023-03-23T10:18:52.579048Z",
     "shell.execute_reply": "2023-03-23T10:18:52.577800Z",
     "shell.execute_reply.started": "2023-03-23T10:12:55.796213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch 0 out of 497 is done\n",
      "epoch:0, batch 50 out of 497 is done\n",
      "epoch:0, batch 100 out of 497 is done\n",
      "epoch:0, batch 150 out of 497 is done\n",
      "epoch:0, batch 200 out of 497 is done\n",
      "epoch:0, batch 250 out of 497 is done\n",
      "epoch:0, batch 300 out of 497 is done\n",
      "epoch:0, batch 350 out of 497 is done\n",
      "epoch:0, batch 400 out of 497 is done\n",
      "epoch:0, batch 450 out of 497 is done\n",
      "epoch:1, batch 0 out of 497 is done\n",
      "epoch:1, batch 50 out of 497 is done\n",
      "epoch:1, batch 100 out of 497 is done\n",
      "epoch:1, batch 150 out of 497 is done\n",
      "epoch:1, batch 200 out of 497 is done\n",
      "epoch:1, batch 250 out of 497 is done\n",
      "epoch:1, batch 300 out of 497 is done\n",
      "epoch:1, batch 350 out of 497 is done\n",
      "epoch:1, batch 400 out of 497 is done\n",
      "epoch:1, batch 450 out of 497 is done\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Fine-tune the BERT model\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad() #set the gradients to zero for each batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #still don't know what it does\n",
    "        \n",
    "        #parameter update based on the current gradient (stored in . grad attribute of a parameter)\n",
    "        optimizer.step()\n",
    "        \n",
    "        #update learning rate with scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f'epoch:{epoch}, batch {i} out of {len(dataset)//batch_size} is done')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4fa7c",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cbecc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T12:03:23.209506Z",
     "iopub.status.busy": "2023-03-22T12:03:23.208530Z",
     "iopub.status.idle": "2023-03-22T12:03:23.806524Z",
     "shell.execute_reply": "2023-03-22T12:03:23.805502Z",
     "shell.execute_reply.started": "2023-03-22T12:03:23.209427Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bert_2_AD.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a64e5",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b50cb5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T12:11:21.163635Z",
     "iopub.status.busy": "2023-03-22T12:11:21.163024Z",
     "iopub.status.idle": "2023-03-22T12:11:23.262650Z",
     "shell.execute_reply": "2023-03-22T12:11:23.261517Z",
     "shell.execute_reply.started": "2023-03-22T12:11:21.163598Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your model architecture\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Load saved model weights\n",
    "model.load_state_dict(torch.load('/kaggle/working/model_bert_1_AD.pth'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fae90b",
   "metadata": {},
   "source": [
    "### SUBMIT Validation/ CREATE bert_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e420e",
   "metadata": {},
   "source": [
    "Here we do two things: we compute predictions for validation and test set that we will submit to the competition. This is done to evaluate how well the bert model performs by itself in the competition. Second, we create the bert_variable. The variable consists of the raw probabilities of the model. Initially we extracted this variable and fed it to the lightGBM model as additional feature. This improved the LGBM model performance but caused data leakage. Thus, we decided to use the probabilities of the Bert model to ensemble with the lightGBM with just the original features. Ensembling avoided data leakage and improved the final accuracy on validation and test by 2.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2450bc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:18:52.581656Z",
     "iopub.status.busy": "2023-03-23T10:18:52.581262Z",
     "iopub.status.idle": "2023-03-23T10:18:55.439808Z",
     "shell.execute_reply": "2023-03-23T10:18:55.438760Z",
     "shell.execute_reply.started": "2023-03-23T10:18:52.581617Z"
    }
   },
   "outputs": [],
   "source": [
    "validation = pd.read_csv('/kaggle/input/train-val-test-bert/validation.csv')['plot']\n",
    "\n",
    "\n",
    "encoded_unseen_data = tokenizer.batch_encode_plus(validation, \n",
    "                                                  add_special_tokens=True, \n",
    "                                                  max_length=max_len, \n",
    "                                                  padding=True, \n",
    "                                                  truncation=True, \n",
    "                                                  return_attention_mask=True, \n",
    "                                                  return_tensors='pt')\n",
    "\n",
    "unseen_dataset = TensorDataset(encoded_unseen_data['input_ids'], encoded_unseen_data['attention_mask'])\n",
    "unseen_dataloader = DataLoader(unseen_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0002515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:19:02.827854Z",
     "iopub.status.busy": "2023-03-23T10:19:02.827504Z",
     "iopub.status.idle": "2023-03-23T10:19:09.765269Z",
     "shell.execute_reply": "2023-03-23T10:19:09.764260Z",
     "shell.execute_reply.started": "2023-03-23T10:19:02.827821Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "bert_variable = []\n",
    "with torch.no_grad():\n",
    "    for batch in unseen_dataloader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, batch_predictions = torch.max(logits, dim=1)\n",
    "        predictions.extend(batch_predictions.tolist())\n",
    "        \n",
    "        probabilities = F.softmax(logits, dim=1)[:,1] #bertvariable\n",
    "        bert_variable.extend(probabilities.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e779196f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T12:08:12.470876Z",
     "iopub.status.busy": "2023-03-22T12:08:12.470480Z",
     "iopub.status.idle": "2023-03-22T12:08:12.477958Z",
     "shell.execute_reply": "2023-03-22T12:08:12.476790Z",
     "shell.execute_reply.started": "2023-03-22T12:08:12.470834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c65990b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:11:17.310376Z",
     "iopub.status.busy": "2023-03-23T10:11:17.307748Z",
     "iopub.status.idle": "2023-03-23T10:11:17.319809Z",
     "shell.execute_reply": "2023-03-23T10:11:17.318695Z",
     "shell.execute_reply.started": "2023-03-23T10:11:17.310336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.926976203918457,\n",
       " 0.9699095487594604,\n",
       " 0.9733518362045288,\n",
       " 0.9611004590988159,\n",
       " 0.7077479958534241,\n",
       " 0.9684246778488159,\n",
       " 0.9697102904319763,\n",
       " 0.965315580368042,\n",
       " 0.9599273204803467,\n",
       " 0.9443084001541138]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_variable[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f1bbcfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:09:47.696252Z",
     "iopub.status.busy": "2023-03-20T14:09:47.695836Z",
     "iopub.status.idle": "2023-03-20T14:09:47.707717Z",
     "shell.execute_reply": "2023-03-20T14:09:47.706778Z",
     "shell.execute_reply.started": "2023-03-20T14:09:47.696217Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions)[0].map({1:\"True\", 0:\"False\"}).to_csv(\"validation_predictions.csv\",\n",
    "                                                                    index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb110e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:19:34.831880Z",
     "iopub.status.busy": "2023-03-23T10:19:34.831167Z",
     "iopub.status.idle": "2023-03-23T10:19:34.842790Z",
     "shell.execute_reply": "2023-03-23T10:19:34.841597Z",
     "shell.execute_reply.started": "2023-03-23T10:19:34.831841Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(bert_variable)[0].to_csv(\"bert_4_validation_prob.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c152ca29",
   "metadata": {},
   "source": [
    "### SUBMIT Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94a0bb",
   "metadata": {},
   "source": [
    "#### do the same we did for validation but now for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2deed5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:19:37.786059Z",
     "iopub.status.busy": "2023-03-23T10:19:37.785660Z",
     "iopub.status.idle": "2023-03-23T10:19:42.243421Z",
     "shell.execute_reply": "2023-03-23T10:19:42.242346Z",
     "shell.execute_reply.started": "2023-03-23T10:19:37.786024Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/train-val-test-bert/test.csv')['plot']\n",
    "\n",
    "encoded_unseen_data = tokenizer.batch_encode_plus(test, \n",
    "                                                  add_special_tokens=True, \n",
    "                                                  max_length=max_len, \n",
    "                                                  padding=True, \n",
    "                                                  truncation=True, \n",
    "                                                  return_attention_mask=True, \n",
    "                                                  return_tensors='pt')\n",
    "\n",
    "unseen_dataset = TensorDataset(encoded_unseen_data['input_ids'], encoded_unseen_data['attention_mask'])\n",
    "unseen_dataloader = DataLoader(unseen_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dea4678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:19:42.246038Z",
     "iopub.status.busy": "2023-03-23T10:19:42.245163Z",
     "iopub.status.idle": "2023-03-23T10:19:49.825097Z",
     "shell.execute_reply": "2023-03-23T10:19:49.824079Z",
     "shell.execute_reply.started": "2023-03-23T10:19:42.245999Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "bert_variable = []\n",
    "with torch.no_grad():\n",
    "    for batch in unseen_dataloader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, batch_predictions = torch.max(logits, dim=1)\n",
    "        predictions.extend(batch_predictions.tolist())\n",
    "        \n",
    "        probabilities = F.softmax(logits, dim=1)[:,1] #bertvariable\n",
    "        bert_variable.extend(probabilities.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa0dd7e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T14:09:59.080228Z",
     "iopub.status.busy": "2023-03-20T14:09:59.079818Z",
     "iopub.status.idle": "2023-03-20T14:09:59.090119Z",
     "shell.execute_reply": "2023-03-20T14:09:59.088954Z",
     "shell.execute_reply.started": "2023-03-20T14:09:59.080184Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions)[0].map({1:\"True\", 0:\"False\"}).to_csv(\"test_predictions.csv\",\n",
    "                                                                    index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "992ccaf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:19:49.827550Z",
     "iopub.status.busy": "2023-03-23T10:19:49.827148Z",
     "iopub.status.idle": "2023-03-23T10:19:49.839066Z",
     "shell.execute_reply": "2023-03-23T10:19:49.837904Z",
     "shell.execute_reply.started": "2023-03-23T10:19:49.827510Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(bert_variable)[0].to_csv(\"bert_4_test_prob.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da45425",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea830ab",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b232a8",
   "metadata": {},
   "source": [
    "The competition gave us 3 useful variables to predict the positive or negative reviews: \"runtime minutes of the movie\", \"number of votes (reviews)\", \"year of the movie\". We added two more variables:\n",
    "\n",
    "- the \"awards\" variable, that was obtained similary to the plots (with gpt-3).\n",
    "- \"genre\" variable. Since we had many genres we chose only the ones with the highest correlation to the target\n",
    "\n",
    "Other preprocessing that was not done in this notebook but in a previous stage using spark was: binning the year variable, scaling the number of votes variable to better fill in the missing values (we found online a dataset of number of votes but 5 years later compared to the year we had, thus scaling resulted in better filling of missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fbf5737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:17:24.508583Z",
     "iopub.status.busy": "2023-03-23T11:17:24.508068Z",
     "iopub.status.idle": "2023-03-23T11:17:24.911484Z",
     "shell.execute_reply": "2023-03-23T11:17:24.910370Z",
     "shell.execute_reply.started": "2023-03-23T11:17:24.508537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>label</th>\n",
       "      <th>awards</th>\n",
       "      <th>1915-1929</th>\n",
       "      <th>1930-1939</th>\n",
       "      <th>1940-1949</th>\n",
       "      <th>1950-1959</th>\n",
       "      <th>1960-1969</th>\n",
       "      <th>1970-1979</th>\n",
       "      <th>...</th>\n",
       "      <th>2000-2009</th>\n",
       "      <th>2010-2019</th>\n",
       "      <th>2020-2023</th>\n",
       "      <th>biography</th>\n",
       "      <th>unknown</th>\n",
       "      <th>horror</th>\n",
       "      <th>noir</th>\n",
       "      <th>drama</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>comedy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>-0.233048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>-0.227816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   runtimeMinutes  numVotes  label  awards  1915-1929  1930-1939  1940-1949  \\\n",
       "0              91 -0.233048      0       0          0          0          0   \n",
       "1             148 -0.227816      0       0          0          0          0   \n",
       "\n",
       "   1950-1959  1960-1969  1970-1979  ...  2000-2009  2010-2019  2020-2023  \\\n",
       "0          0          1          0  ...          0          0          0   \n",
       "1          0          0          0  ...          0          1          0   \n",
       "\n",
       "   biography  unknown  horror  noir  drama  sci-fi  comedy  \n",
       "0          0        0       1     0      0       0       0  \n",
       "1          0        1       0     0      0       0       0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PREPROCESS\n",
    "train = pd.read_csv('/kaggle/input/train-val-test-bert/train.csv')\n",
    "\n",
    "#drop columns\n",
    "train = train.drop(['_c0', 'tconst'], axis=1)\n",
    "\n",
    "#randomized for same train-test split for \n",
    "train = train.sample(frac=1, random_state=420).reset_index(drop=True)\n",
    "\n",
    "#doing correlation matrix of only GENRES(indeces 18,19,20,...) and LABEL(index 4)\n",
    "corr_matrix = train.iloc[:,[4] + list(range(18, train.shape[1]))].corr()\n",
    "\n",
    "#compute list of genres to keep\n",
    "genres_to_keep = abs(corr_matrix['label']).sort_values(ascending=False)[1:8].index.values\n",
    "\n",
    "#compute all_genres, then obtain genres_to_remove by subtracting all_genres and genres_to_keep\n",
    "all_genres = train.iloc[:, 18:].columns.values\n",
    "genres_to_remove = set(all_genres) - set(genres_to_keep)\n",
    "\n",
    "#drop genres_to_remove\n",
    "train = train.drop(list(genres_to_remove), axis=1)\n",
    "\n",
    "# drop titles and plot\n",
    "train = train.drop(['primaryTitle', 'startYear', 'plot'], axis=1)\n",
    "\n",
    "# change labels to int\n",
    "train['label'] = train['label'].astype(int)\n",
    "\n",
    "#view\n",
    "train.iloc[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82965d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:17:27.448809Z",
     "iopub.status.busy": "2023-03-23T11:17:27.448101Z",
     "iopub.status.idle": "2023-03-23T11:17:27.456426Z",
     "shell.execute_reply": "2023-03-23T11:17:27.455360Z",
     "shell.execute_reply.started": "2023-03-23T11:17:27.448771Z"
    }
   },
   "outputs": [],
   "source": [
    "#NEW TRAIN TEST SPLIT\n",
    "train_size = int(0.8 * len(train))\n",
    "\n",
    "y = train[\"label\"]\n",
    "X = train.drop([\"label\"],axis=1)\n",
    "X_train, X_test, y_train, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba040b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:18:56.034047Z",
     "iopub.status.busy": "2023-03-23T11:18:56.033561Z",
     "iopub.status.idle": "2023-03-23T11:18:56.202295Z",
     "shell.execute_reply": "2023-03-23T11:18:56.201263Z",
     "shell.execute_reply.started": "2023-03-23T11:18:56.034002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       774\n",
      "           1       0.79      0.69      0.74       818\n",
      "\n",
      "    accuracy                           0.75      1592\n",
      "   macro avg       0.75      0.75      0.75      1592\n",
      "weighted avg       0.75      0.75      0.75      1592\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "\n",
      " [[624 150]\n",
      " [253 565]]\n"
     ]
    }
   ],
   "source": [
    "#useful imports\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,RepeatedStratifiedKFold,train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create lgbm object\n",
    "clf = lgb.LGBMClassifier()\n",
    "\n",
    "# Train lgbm\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "# y_pred = (clf.predict_proba(X_test)[:,1] >= 0.89).astype(bool) # set threshold as 0.882 (random number)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"confusion_matrix:\\n\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f38a3697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:11:43.411664Z",
     "iopub.status.busy": "2023-03-23T11:11:43.411295Z",
     "iopub.status.idle": "2023-03-23T11:11:45.732789Z",
     "shell.execute_reply": "2023-03-23T11:11:45.730871Z",
     "shell.execute_reply.started": "2023-03-23T11:11:43.411629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.2.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "## Loading LightGBM model TRAINED AN ALL DATA (note that the previous one is trained on 80%)\n",
    "import pickle\n",
    "\n",
    "# Load the saved model from a file\n",
    "with open('/kaggle/input/bert-probs-model-trained-all-data/lgbm_model_AD.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2be5c05a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:11:49.207173Z",
     "iopub.status.busy": "2023-03-23T11:11:49.206399Z",
     "iopub.status.idle": "2023-03-23T11:11:49.269442Z",
     "shell.execute_reply": "2023-03-23T11:11:49.268282Z",
     "shell.execute_reply.started": "2023-03-23T11:11:49.207131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>awards</th>\n",
       "      <th>1915-1929</th>\n",
       "      <th>1930-1939</th>\n",
       "      <th>1940-1949</th>\n",
       "      <th>1950-1959</th>\n",
       "      <th>1960-1969</th>\n",
       "      <th>1970-1979</th>\n",
       "      <th>1980-1989</th>\n",
       "      <th>...</th>\n",
       "      <th>2000-2009</th>\n",
       "      <th>2010-2019</th>\n",
       "      <th>2020-2023</th>\n",
       "      <th>biography</th>\n",
       "      <th>unknown</th>\n",
       "      <th>horror</th>\n",
       "      <th>noir</th>\n",
       "      <th>drama</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>comedy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>-0.238496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>-0.256873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>-0.259097</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>-0.045994</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>-0.212464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   runtimeMinutes  numVotes  awards  1915-1929  1930-1939  1940-1949  \\\n",
       "0             148 -0.238496       1          0          0          0   \n",
       "1              65 -0.256873       0          1          0          0   \n",
       "2             166 -0.259097       0          1          0          0   \n",
       "3              74 -0.045994       0          1          0          0   \n",
       "4             143 -0.212464       0          1          0          0   \n",
       "\n",
       "   1950-1959  1960-1969  1970-1979  1980-1989  ...  2000-2009  2010-2019  \\\n",
       "0          0          0          0          0  ...          0          0   \n",
       "1          0          0          0          0  ...          0          0   \n",
       "2          0          0          0          0  ...          0          0   \n",
       "3          0          0          0          0  ...          0          0   \n",
       "4          0          0          0          0  ...          0          0   \n",
       "\n",
       "   2020-2023  biography  unknown  horror  noir  drama  sci-fi  comedy  \n",
       "0          0          0        1       0     0      0       0       0  \n",
       "1          0          0        1       0     0      0       0       0  \n",
       "2          0          0        1       0     0      0       0       0  \n",
       "3          0          0        0       0     0      0       0       1  \n",
       "4          0          0        1       0     0      0       0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation and test are non labelled datasets, they are used to make predictions\n",
    "#predictions are then sent to competition\n",
    "validation = pd.read_csv('/kaggle/input/train-val-test-bert/validation.csv')\n",
    "test = pd.read_csv('/kaggle/input/train-val-test-bert/test.csv')\n",
    "\n",
    "#drop not useful genres\n",
    "all_genres_val = validation.iloc[:, 19:].columns.values #val \n",
    "genres_to_remove_val = set(all_genres_val) - set(genres_to_keep) #val\n",
    "validation = validation.drop(list(genres_to_remove_val), axis=1)\n",
    "\n",
    "all_genres_test = test.iloc[:, 19:].columns.values #test\n",
    "genres_to_remove_test = set(all_genres_test) - set(genres_to_keep) #test\n",
    "test = test.drop(list(genres_to_remove_test), axis=1)\n",
    "\n",
    "#drop also other columns\n",
    "validation = validation.drop(['Unnamed: 0', 'tconst','primaryTitle','startYear', 'plot'], axis=1)\n",
    "test = test.drop(['Unnamed: 0', 'tconst','primaryTitle','startYear', 'plot'], axis=1)\n",
    "\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b082afdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:11:52.081404Z",
     "iopub.status.busy": "2023-03-23T11:11:52.081019Z",
     "iopub.status.idle": "2023-03-23T11:11:52.109562Z",
     "shell.execute_reply": "2023-03-23T11:11:52.108657Z",
     "shell.execute_reply.started": "2023-03-23T11:11:52.081368Z"
    }
   },
   "outputs": [],
   "source": [
    "#get lightGBM probabilties for ensembling\n",
    "lgbm_validation_prob = clf.predict_proba(validation)[:,1]\n",
    "lgbm_test_prob = clf.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d0a4dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:12:00.081084Z",
     "iopub.status.busy": "2023-03-23T11:12:00.080683Z",
     "iopub.status.idle": "2023-03-23T11:12:00.090683Z",
     "shell.execute_reply": "2023-03-23T11:12:00.089267Z",
     "shell.execute_reply.started": "2023-03-23T11:12:00.081046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97141467, 0.8818765 , 0.8873568 , 0.96661709, 0.95302602,\n",
       "       0.98362559, 0.95834933, 0.82028069, 0.96467178, 0.91221948])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_validation_prob[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69271686",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9d6f",
   "metadata": {},
   "source": [
    "#### we use 4 different berts (that are trained starting from different parameter initialization) + lightGBM and ensemble the 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6792d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:12:44.884286Z",
     "iopub.status.busy": "2023-03-23T11:12:44.883891Z",
     "iopub.status.idle": "2023-03-23T11:12:44.924384Z",
     "shell.execute_reply": "2023-03-23T11:12:44.923461Z",
     "shell.execute_reply.started": "2023-03-23T11:12:44.884243Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_1_validation_prob = pd.read_csv('/kaggle/input/bert-probs-model-trained-all-data/bert_1_validation_prob.csv', header=None).values.squeeze()\n",
    "bert_1_test_prob = pd.read_csv('/kaggle/input/bert-probs-model-trained-all-data/bert_1_test_prob.csv', header=None).values.squeeze()\n",
    "\n",
    "bert_2_validation_prob = pd.read_csv('/kaggle/input/bert-probs-model-trained-all-data/bert_2_validation_prob.csv', header=None).values.squeeze()\n",
    "bert_2_test_prob = pd.read_csv('/kaggle/input/bert-probs-model-trained-all-data/bert_2_test_prob.csv', header=None).values.squeeze()\n",
    "\n",
    "bert_3_validation_prob = pd.read_csv('/kaggle/input/bert-3/bert_3_validation_prob.csv', header=None).values.squeeze()\n",
    "bert_3_test_prob = pd.read_csv('/kaggle/input/bert-3/bert_3_test_prob.csv', header=None).values.squeeze()\n",
    "\n",
    "bert_4_validation_prob = pd.read_csv('/kaggle/input/bert-3-4/bert_4_validation_prob.csv', header=None).values.squeeze()\n",
    "bert_4_test_prob = pd.read_csv('/kaggle/input/bert-3-4/bert_4_test_prob.csv', header=None).values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dd091fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:12:47.773777Z",
     "iopub.status.busy": "2023-03-23T11:12:47.773152Z",
     "iopub.status.idle": "2023-03-23T11:12:47.781600Z",
     "shell.execute_reply": "2023-03-23T11:12:47.780282Z",
     "shell.execute_reply.started": "2023-03-23T11:12:47.773738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96563786, 0.97061265, 0.96488744, 0.96918386, 0.59087336,\n",
       "       0.96952403, 0.96759397, 0.9688496 , 0.96891809, 0.9014008 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_1_validation_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b35777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:13:04.488170Z",
     "iopub.status.busy": "2023-03-23T11:13:04.487634Z",
     "iopub.status.idle": "2023-03-23T11:13:04.497373Z",
     "shell.execute_reply": "2023-03-23T11:13:04.496276Z",
     "shell.execute_reply.started": "2023-03-23T11:13:04.488122Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0.125*bert_1 + 0.125*bert_2 + 0.125*bert_3 + 0.125*bert_4 + 0.5*lightGBM\n",
    "\n",
    "import numpy as np\n",
    "combined_validation_4berts = np.round(np.array(bert_1_validation_prob)*0.125 + np.array(bert_2_validation_prob)*0.125 + np.array(bert_3_validation_prob)*0.125 + np.array(bert_4_validation_prob)*0.125 + lgbm_validation_prob*0.5)\n",
    "combined_test_4berts = np.round(np.array(bert_1_test_prob)*0.125 + np.array(bert_2_test_prob)*0.125 + np.array(bert_3_test_prob)*0.125 + np.array(bert_4_test_prob)*0.125 + lgbm_test_prob*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26499a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T11:13:06.304321Z",
     "iopub.status.busy": "2023-03-23T11:13:06.303431Z",
     "iopub.status.idle": "2023-03-23T11:13:06.312576Z",
     "shell.execute_reply": "2023-03-23T11:13:06.311149Z",
     "shell.execute_reply.started": "2023-03-23T11:13:06.304271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_validation_4berts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd58eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving predictions in format required from the competition\n",
    "pd.DataFrame(combined_validation_4berts)[0].map({1:\"True\", 0:\"False\"}).to_csv(\"validation_ensemble_4bert.csv\",\n",
    "                                                                    index=False, header=False)\n",
    "pd.DataFrame(combined_test_4berts)[0].map({1: \"True\", 0: \"False\"}).to_csv(\"test_ensemble_4bert.csv\",\n",
    "                                                                  index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
